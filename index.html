<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>LEGO Instruction Deconstructor - Work in Progress!!!</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.14.305/pdf.min.js"></script>
  <script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>

  <style>
    body { font-family: sans-serif; margin: 20px; }
    canvas { display: none; }
    #results { margin-top: 20px; }
    .page-block { margin-bottom: 20px; padding: 10px; border: 1px solid #ccc; border-radius: 8px; }
  </style>
</head>
<body>
  <h1>LEGO Instruction Deconstructor - Work in Progress!!!</h1>
  <input type="file" id="pdfUpload" accept=".pdf" />
  <div id="results"></div>

<script>
const IMG_WIDTH = 256;
const IMG_HEIGHT = 192;


  // rest of your code
</script>
<script>
// Load ONNX model (local or from URL)

// Get outputs

    const pageLabels = ['finish', 'index', 'extra', 'decisionpage', 'steppage'];
    const sectionLabels = [
        ['pageno'],
        ['pageno', 'part', 'repeat'],
        ['pageno'],
        ['pageno', 'splitdecision'],
        ['bagset', 'dontreadpartstep', 'dontreadrepeat', 'extrabag', 'minifig', 'minifigpart', 'numberstep', 'objects', 'pageno', 'partstep', 'repeat', 'step', 'subbuild', 'wholeminiig'],
    ];
    const imageDir = 'model/dataset';

    // Your existing function to preprocess the image
    async function processImage(img) {
      return tf.tidy(() => {
        const tensor = tf.browser.fromPixels(img)
          .resizeNearestNeighbor([IMG_HEIGHT, IMG_WIDTH])
          .toFloat()
          .div(255.0);
        return tensor.expandDims(0);
      });
    }
async function detectExecutionProvider() {
  // Check for WebGL support
  const webglSupported = (() => {
    try {
      const canvas = document.createElement('canvas');
      return !!(window.WebGLRenderingContext && (
        canvas.getContext('webgl') || canvas.getContext('experimental-webgl')
      ));
    } catch (e) {
      return false;
    }
  })();

  if (webglSupported) {
    return ['webgl', 'wasm'];
  } else if (typeof ort.env.wasm !== 'undefined') {
    // Check if WASM is supported
    return ['wasm'];
  } else {
    // Fallback to CPU
    return ['cpu'];
  }
}
async function drawBoxesOnTensorImage(tensor, boxes, labels, scale = 1) {
const [height, width] = tensor.shape.slice(0, 2);
const canvas = document.createElement('canvas');
const ctx = canvas.getContext('2d');

canvas.width = width;
canvas.height = height;

// Optional scale factor (1 if boxes are in pixels, width/height if normalized)
const scaleX = width;
const scaleY = height;

// Example box list and labels
// const boxes = [[0.1, 0.2, 0.3, 0.3], ...]; // normalized
// const labels = ['brick', 'minifig', ...]; // same length as boxes

await tf.browser.toPixels(tensor, canvas).then(() => {
  ctx.lineWidth = 2;
  ctx.strokeStyle = 'red';
  ctx.font = '16px sans-serif';
  ctx.fillStyle = 'red';

  boxes.forEach((box, i) => {
    const [x, y, w, h] = box;

    // If boxes are normalized (0-1), scale them to pixel values
    //const absX = x * scaleX;
    //const absY = y * scaleY;
    //const absW = w * scaleX;
    //const absH = h * scaleY;
    const absX = x;
    const absY = y;
    const absW = w;
    const absH = h;

    // Draw bounding box
    ctx.strokeRect(absX, absY, absW, absH);

    // Draw label text
    const label = labels?.[i] || 'label';
    //ctx.fillText(label, absX + 4, absY + 16); // offset slightly inside the box
  });
});

return canvas.toDataURL();

}


async function loadONNXModel(filename) {
  const providers = await detectExecutionProvider();
  console.log('Using ONNX execution provider:', providers[0]);

  onnxSession = await ort.InferenceSession.create(filename, {
    executionProviders: providers
  });
  return onnxSession
}

async function predictONNX(session, tensor, labelList, threshold = 0.5) {
  const transposed = tf.tidy(() => tensor.transpose([0, 3, 1, 2])); // [1, 3, 64, 64]
  const inputTensor = new ort.Tensor('float32', transposed.dataSync(), [1, 3, IMG_HEIGHT, IMG_WIDTH]);
  tf.dispose(transposed);

  const inputName = session.inputNames[0];
  const output = await session.run({ [inputName]: inputTensor });

  const outputTensor = output[session.outputNames[0]]; // ‚Üê single output

  //console.log(Object.values(outputTensor.data));
  const labels = [];
  const firstBox = outputTensor.data.slice(0, 18);
//console.log('First prediction raw data:', firstBox);

//      console.log('Output shape:', outputTensor.dims[0]);
//    console.log('Output shape:', outputTensor.dims[2]);
//  console.log('Output shape:', outputTensor.dims[1]);  // e.g. [N, M] or [N, 6] etc
//      console.log('Output shape:', Object.keys(outputTensor.cpuData));
//console.log('Output length:', outputTensor.data.length);
//console.log('Output sample:', outputTensor.data.slice(0, 20));
const raw = outputTensor.data;
const numChannels = 18;
const numPreds = 84;

const reshaped = [];
const bbox = [];
for (let i = 0; i < numPreds; i++) {
  const row = [];
  for (let j = 0; j < numChannels; j++) {
    row.push(raw[j * numPreds + i]);  // Transpose: [channel][prediction]
  }
  reshaped.push(row);
}

for (const row of reshaped) {
  const [x, y, w, h, ...classScores] = row;
  const bestClassIndex = classScores.indexOf(Math.max(...classScores));
  const label = labelList[bestClassIndex];
  //console.log(`Predicted class ${label} at [${x}, ${y}, ${w}, ${h}]`);
  labels.push({ label });
  bbox.push([x, y, w, h]);
}
  return [{ boxes: bbox, labels: labels }];
}




    let pageModel, finishModel, indexModel, extraModel, decisionpageModel, steppageModel;
    async function predictModel(model, tensor){
        return await model.predict(tensor).data();
    }

async function loadModels() {
  const prefix = "https://autoupdatingbsod.github.io/LEGO-Instruction-Deconstructor";
  const [
    pageModel,
  ] = await Promise.all([
    tf.loadLayersModel(`${prefix}/model/page_type/page-model.json`)
  ]);
  const finishModel = await loadONNXModel(prefix+'/model/section_type/steppage.onnx');
  const indexModel = await loadONNXModel(prefix+'/model/section_type/steppage.onnx');
  const extraModel = await loadONNXModel(prefix+'/model/section_type/steppage.onnx');
  const decisionpageModel = await loadONNXModel(prefix+'/model/section_type/steppage.onnx');
  const steppageModel = await loadONNXModel(prefix+'/model/section_type/steppage.onnx');

  return {
    pageModel,
    finishModel,
    indexModel,
    extraModel,
    decisionpageModel,
    steppageModel
  };
}
    async function handlePDF(file) {
      
      let models = await loadModels();
      pageModel = models.pageModel;
    finishModel = models.finishModel;
    indexModel = models.indexModel;
    extraModel = models.extraModel;
    decisionpageModel = models.decisionpageModel;
    steppageModel = models.steppageModel;

      
     
      
      
      const pdfData = new Uint8Array(await file.arrayBuffer());
      const pdf = await pdfjsLib.getDocument({ data: pdfData }).promise;

      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');

      for (let pageNum = 1; pageNum <= pdf.numPages; pageNum++) {
        const page = await pdf.getPage(pageNum);
        const viewport = page.getViewport({ scale: 2.0 });

        canvas.width = viewport.width;
        canvas.height = viewport.height;

        await page.render({ canvasContext: ctx, viewport }).promise;
        const imgTensor = tf.browser.fromPixels(canvas)
          .resizeNearestNeighbor([IMG_HEIGHT, IMG_WIDTH])
          .toFloat()
          .div(255)
          .expandDims(0);

        // PAGE PREDICTION (Single label)
        const pagePred = pageModel.predict(imgTensor);
        const pageIndex = (await pagePred.argMax(-1).data());
        const pageLabel = pageLabels[pageIndex];
                    let sectionPred = null;
          const val = pageIndex;
          if (val > 0.5) {
            //document.getElementById('results').innerHTML +=  '- PAGE: '+pageLabel+' '+(val)+'\n';
          
            let idi = null;

          
        switch (pageLabel) {
          case "finish":
            idi = 0;
            //sectionPred = await predictModel(finishModel, imgTensor);
            break;
          case "index":
            idi = 1;
            //sectionPred = await predictModel(indexModel, imgTensor);
            break;
          case "extra":
            idi = 2;
            //sectionPred = await predictModel(extraModel, imgTensor);
            break;
          case "decisionpage":
            idi = 3;
            //sectionPred = await predictModel(decisionpageModel, imgTensor);
            break;
          case "steppage":
            idi = 4;
            sectionPred = await predictONNX(steppageModel, imgTensor, sectionLabels[idi]);  // use ONNX
            break;
        }

          

        }
        // SECTION PREDICTION (Multi-label)
        //const sectionCounts = {};
        //let sc = 0;
        //if (sectionPred) {
           //sectionPred.forEach((result, idx) => {
            //console.log(`Detection ${idx + 1}:`);
            //console.log("  Box:", result.bbox);
//console.log("  Labels:", result.labels.map(l => l.label).join(", "));

            //sc = idx;
          //});
          
        //}

        //displayResults(pageNum, pageLabel, sectionCounts);
        tf.dispose([imgTensor, pagePred, sectionPred]);
      }
  }
    async function renderPageToCanvas(pdfPage) {
      const viewport = pdfPage.getViewport({ scale: 2 });
      const canvas = document.createElement('canvas');
      canvas.width = viewport.width;
      canvas.height = viewport.height;
      const context = canvas.getContext('2d');
      await pdfPage.render({ canvasContext: context, viewport: viewport }).promise;
      return canvas;
    }

    async function displayResults(pageNum, pageLabel, sectionPred, imgTensor) {
      const container = document.getElementById('results');
      const block = document.createElement('div');
      block.className = 'page-block';

      let html = '<strong>Page '+pageNum+':</strong> '+pageLabel+'<br>';
      if (Object.keys(sectionPred).length > 0) {
        html += '<em>Sections:</em><br>';
        console.log(Object.keys(sectionPred[0]));
        var img = await drawBoxesOnTensorImage(imgTensor.squeeze(), sectionPred[0].boxes, sectionPred[0].labels);
        html += "<img src='"+img+"' alt='Prediction result for page "+pageNum+"' />";
        
      } else {
        html += '<em>No section categories detected above threshold.</em>';
      }

      block.innerHTML = html;
      container.appendChild(block);
    }

    document.getElementById('pdfUpload').addEventListener('change', async (e) => {
      document.getElementById('results').innerHTML = '';
      let log = document.getElementById('results');
      const file = e.target.files[0];
      if (!file || file.type !== "application/pdf") {
        log.textContent = "Please upload a valid PDF.";
        return;
      }

      log.textContent = `Loading models and reading PDF...\n`;

      const { pageModel, finishModel, indexModel, extraModel, decisionpageModel, steppageModel } = await loadModels();
      const fileURL = URL.createObjectURL(file);
      const pdf = await pdfjsLib.getDocument(fileURL).promise;

      for (let i = 1; i <= pdf.numPages; i++) {
        const page = await pdf.getPage(i);
        const canvas = await renderPageToCanvas(page);
        const tensor = await processImage(canvas);

        const pagePred = await pageModel.predict(tensor).data();
        

        //log.textContent += `\nPage ${i} predictions:\n`;
            let idi = null;
        // Format multi-label output
        for (let idx = 0; idx < pagePred.length; idx++) {
          const val = pagePred[idx];
          if (val > 0.5) {
            //log.textContent += ` - PAGE: ${pageLabels[idx]} (${val.toFixed(2)})\n`;
          

            let sectionPred = null;
          
            switch (pageLabels[idx]) {
              case "finish":
                idi = 0;
                //sectionPred = await predictModel(finishModel, tensor);
                break;
              case "index":
                idi = 1;
                //sectionPred = await predictModel(indexModel, tensor);
                break;
              case "extra":
                idi = 2;
                //sectionPred = await predictModel(extraModel, tensor);
                break;
              case "decisionpage":
                idi = 3;
                //sectionPred = await predictModel(decisionpageModel, tensor);
                break;
              case "steppage":
                idi = 4;
                sectionPred = await predictONNX(steppageModel, tensor, sectionLabels[idi]);  // use ONNX
                await displayResults(i, pageLabels[idi], sectionPred, tensor);
                break;
            }
          
        //const sectionCounts = {};
        //let sc = 0;
        //if (sectionPred) {
        //   sectionPred.forEach((result, idx) => {
        //    //console.log(`Detection ${idx + 1}:`);
        //    //console.log("  Box:", result.bbox);
        //    //console.log("  Labels:", result.labels.join(", "));
        //    //console.log("  Labels:", result.labels.map(l => l.label).join(", "));
        //    sc = idx;
        //  });
        //  
        //}
          }
        }


        //sectionPred.forEach((val, idx) => {
        //  if (val > 0.5) log.textContent += ` - SECTION: ${sectionCategories[idx]} (${val.toFixed(2)})\n`;
       // });

        tf.dispose([tensor]);
      }

      log.textContent += `\nDone processing all pages.`;
      if (!file) return;

      await handlePDF(file);
    });
  </script>
</body>
</html>
