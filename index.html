<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>LEGO Page & Section Classifier</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.14.305/pdf.min.js"></script>
  <script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>

  <style>
    body { font-family: sans-serif; margin: 20px; }
    canvas { display: none; }
    #results { margin-top: 20px; }
    .page-block { margin-bottom: 20px; padding: 10px; border: 1px solid #ccc; border-radius: 8px; }
  </style>
</head>
<body>
  <h1>LEGO PDF Page & Section Classifier</h1>
  <input type="file" id="pdfUpload" accept=".pdf" />
  <div id="results"></div>

<script>



  // rest of your code
</script>
<script>
// Load ONNX model (local or from URL)

// Get outputs

    const pageLabels = ['finish', 'index', 'extra', 'decisionpage', 'steppage'];
    const sectionLabels = [
        ['pageno'],
        ['pageno', 'part', 'repeat'],
        ['pageno'],
        ['pageno', 'splitdecision'],
        ['bagset', 'dontreadpartstep', 'dontreadrepeat', 'extrabag', 'minifig', 'minifigpart', 'numberstep', 'objects', 'pageno', 'partstep', 'repeat', 'step', 'subbuild', 'wholeminiig'],
    ];
    const imageDir = 'model/dataset';

    // Your existing function to preprocess the image
    async function processImage(img) {
      return tf.tidy(() => {
        const tensor = tf.browser.fromPixels(img)
          .resizeNearestNeighbor([64, 64])
          .toFloat()
          .div(255.0);
        return tensor.expandDims(0);
      });
    }
async function detectExecutionProvider() {
  // Check for WebGL support
  const webglSupported = (() => {
    try {
      const canvas = document.createElement('canvas');
      return !!(window.WebGLRenderingContext && (
        canvas.getContext('webgl') || canvas.getContext('experimental-webgl')
      ));
    } catch (e) {
      return false;
    }
  })();

  if (webglSupported) {
    return ['webgl', 'wasm'];
  } else if (typeof ort.env.wasm !== 'undefined') {
    // Check if WASM is supported
    return ['wasm'];
  } else {
    // Fallback to CPU
    return ['cpu'];
  }
}


async function loadONNXModel(filename) {
  const providers = await detectExecutionProvider();
  console.log('Using ONNX execution provider:', providers[0]);

  onnxSession = await ort.InferenceSession.create(filename, {
    executionProviders: providers
  });
  return onnxSession
}

async function predictONNX(session, tensor, labelList, threshold = 0.5) {
  const transposed = tf.tidy(() => tensor.transpose([0, 3, 1, 2]));
  const inputTensor = new ort.Tensor('float32', transposed.dataSync(), [1, 3, 64, 64]);
  tf.dispose(transposed);

  const output = await session.run({ input: inputTensor });

  const boxes = output['boxes'].data; // Flattened [N * 4]
  const scores = output['scores'].data; // Flattened [N * num_classes]

  const numBoxes = boxes.length / 4;
  const numClasses = labelList.length;
  const results = [];

  for (let i = 0; i < numBoxes; i++) {
    const bbox = boxes.slice(i * 4, (i + 1) * 4);
    const labelScores = scores.slice(i * numClasses, (i + 1) * numClasses);
    
    const labels = labelScores
      .map((prob, idx) => (prob > threshold ? labelList[idx] : null))
      .filter(Boolean);

    if (labels.length > 0) {
      results.push({ bbox, labels });
    }
  }

  return results;
}



    let pageModel, finishModel, indexModel, extraModel, decisionpageModel, steppageModel;
    async function predictModel(model, tensor){
        return await model.predict(tensor).data();
    }
let steppageSession;

async function loadModels() {
  const prefix = "https://autoupdatingbsod.github.io/LSBPSE";
  const [
    pageModel,
    finishModel,
    indexModel,
    extraModel,
    decisionpageModel
  ] = await Promise.all([
    tf.loadLayersModel(`${prefix}/model/page_type/page-model.json`),
    tf.loadLayersModel(`${prefix}/model/section_type/finish-model.json`),
    tf.loadLayersModel(`${prefix}/model/section_type/index-model.json`),
    tf.loadLayersModel(`${prefix}/model/section_type/extra-model.json`),
    tf.loadLayersModel(`${prefix}/model/section_type/decisionpage-model.json`)
  ]);

  steppageSession = await loadONNXModel(prefix+'/model/section_type/steppage.onnx');

  return {
    pageModel,
    finishModel,
    indexModel,
    extraModel,
    decisionpageModel,
    steppageSession
  };
}

    async function handlePDF(file) {
      const pdfData = new Uint8Array(await file.arrayBuffer());
      const pdf = await pdfjsLib.getDocument({ data: pdfData }).promise;

      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');

      for (let pageNum = 1; pageNum <= pdf.numPages; pageNum++) {
        const page = await pdf.getPage(pageNum);
        const viewport = page.getViewport({ scale: 2.0 });

        canvas.width = viewport.width;
        canvas.height = viewport.height;

        await page.render({ canvasContext: ctx, viewport }).promise;
        const imgTensor = tf.browser.fromPixels(canvas)
          .resizeNearestNeighbor([64, 64])
          .toFloat()
          .div(255)
          .expandDims(0);

        // PAGE PREDICTION (Single label)
        const pagePred = pageModel.predict(imgTensor);
        const pageIndex = (await pagePred.argMax(-1).data());
        const pageLabel = pageLabels[pageIndex];
                    let sectionPred = null;
          const val = pageIndex;
          if (val > 0.5) {
            //document.getElementById('results').innerHTML +=  '- PAGE: '+pageLabel+' '+(val)+'\n';
          
            let idi = null;

          
        switch (pageLabel) {
          case "finish":
            idi = 0;
            //sectionPred = await predictModel(finishModel, imgTensor);
            break;
          case "index":
            idi = 1;
            //sectionPred = await predictModel(indexModel, imgTensor);
            break;
          case "extra":
            idi = 2;
            //sectionPred = await predictModel(extraModel, imgTensor);
            break;
          case "decisionpage":
            idi = 3;
            //sectionPred = await predictModel(decisionpageModel, imgTensor);
            break;
          case "steppage":
            idi = 4;
            sectionPred = await predictONNX(steppageModel, imgTensor, sectionLabels[idi]);  // use ONNX
            break;
        }

          

        }
        // SECTION PREDICTION (Multi-label)
        const sectionCounts = {};
        let sc = 0;
        if (sectionPred) {
           sectionPred.forEach((result, idx) => {
            console.log(`Detection ${idx + 1}:`);
            console.log("  Box:", result.bbox);
            console.log("  Labels:", result.labels.join(", "));
            sc = idx;
          });
          
        }

        //displayResults(pageNum, pageLabel, sectionCounts);
        tf.dispose([imgTensor, pagePred, sectionPred]);
      }
  }
    async function renderPageToCanvas(pdfPage) {
      const viewport = pdfPage.getViewport({ scale: 2 });
      const canvas = document.createElement('canvas');
      canvas.width = viewport.width;
      canvas.height = viewport.height;
      const context = canvas.getContext('2d');
      await pdfPage.render({ canvasContext: context, viewport: viewport }).promise;
      return canvas;
    }

    function displayResults(pageNum, pageLabel, sectionCounts) {
      const container = document.getElementById('results');
      const block = document.createElement('div');
      block.className = 'page-block';

      let html = '<strong>Page '+pageNum+':</strong> '+pageLabel+'<br>';
      if (Object.keys(sectionCounts).length > 0) {
        html += '<em>Sections:</em><br>';
        for (const [label, count] of Object.entries(sectionCounts)) {
          html += '&nbsp;&nbsp;- '+label+': '+count+'<br>';
        }
      } else {
        html += '<em>No section categories detected above threshold.</em>';
      }

      block.innerHTML = html;
      container.appendChild(block);
    }

    document.getElementById('pdfUpload').addEventListener('change', async (e) => {
      document.getElementById('results').innerHTML = '';
      let log = document.getElementById('results');
      const file = e.target.files[0];
      if (!file || file.type !== "application/pdf") {
        log.textContent = "Please upload a valid PDF.";
        return;
      }

      log.textContent = `Loading models and reading PDF...\n`;

      const { pageModel, finishModel, indexModel, extraModel, decisionpageModel, steppageModel } = await loadModels();
      const fileURL = URL.createObjectURL(file);
      const pdf = await pdfjsLib.getDocument(fileURL).promise;

      for (let i = 1; i <= pdf.numPages; i++) {
        const page = await pdf.getPage(i);
        const canvas = await renderPageToCanvas(page);
        const tensor = await processImage(canvas);

        const pagePred = await pageModel.predict(tensor).data();
        

        log.textContent += `\nPage ${i} predictions:\n`;

        // Format multi-label output
        for (let idx = 0; idx < pagePred.length; idx++) {
          const val = pagePred[idx];
          if (val > 0.5) {
            log.textContent += ` - PAGE: ${pageLabels[idx]} (${val.toFixed(2)})\n`;
          
            let idi = null;
            let sectionPred = null;
          
            switch (pageLabels[idx]) {
              case "finish":
                idi = 0;
                //sectionPred = await predictModel(finishModel, tensor);
                break;
              case "index":
                idi = 1;
                //sectionPred = await predictModel(indexModel, tensor);
                break;
              case "extra":
                idi = 2;
                //sectionPred = await predictModel(extraModel, tensor);
                break;
              case "decisionpage":
                idi = 3;
                //sectionPred = await predictModel(decisionpageModel, tensor);
                break;
              case "steppage":
                idi = 4;
                sectionPred = await predictONNX(steppageModel, tensor, sectionLabels[idi]);  // use ONNX
                break;
            }
          
        const sectionCounts = {};
        let sc = 0;
        if (sectionPred) {
           sectionPred.forEach((result, idx) => {
            console.log(`Detection ${idx + 1}:`);
            console.log("  Box:", result.bbox);
            console.log("  Labels:", result.labels.join(", "));
            sc = idx;
          });
          
        }
          }
        }


        //sectionPred.forEach((val, idx) => {
        //  if (val > 0.5) log.textContent += ` - SECTION: ${sectionCategories[idx]} (${val.toFixed(2)})\n`;
       // });

        tf.dispose([tensor]);
      }

      log.textContent += `\nDone processing all pages.`;
      if (!file) return;
      await loadModels();
      await handlePDF(file);
    });
  </script>
</body>
</html>
