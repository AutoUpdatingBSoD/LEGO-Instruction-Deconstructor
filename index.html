<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>LEGO Page & Section Classifier</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdf.js/2.14.305/pdf.min.js"></script>
  <script src="https://code.jquery.com/jquery-3.7.1.min.js" integrity="sha256-/JqT3SQfawRcv/BIHPThkBvs0OEvtFFmqPF/lYI/Cxo=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>

  <style>
    body { font-family: sans-serif; margin: 20px; }
    canvas { display: none; }
    #results { margin-top: 20px; }
    .page-block { margin-bottom: 20px; padding: 10px; border: 1px solid #ccc; border-radius: 8px; }
  </style>
</head>
<body>
  <h1>LEGO PDF Page & Section Classifier</h1>
  <input type="file" id="pdfUpload" accept=".pdf" />
  <div id="results"></div>

  <script>
        import * as ort from 'onnxruntime-web';

// Load ONNX model (local or from URL)

// Get outputs

    const pageLabels = ['finish', 'index', 'extra', 'decisionpage', 'steppage'];
    const sectionLabels = [
        ['pageno'],
        ['pageno', 'part', 'repeat'],
        ['pageno'],
        ['pageno', 'splitdecision'],
        ['bagset', 'dontreadpartstep', 'dontreadrepeat', 'extrabag', 'minifig', 'minifigpart', 'numberstep', 'objects', 'pageno', 'partstep', 'repeat', 'step', 'subbuild', 'wholeminiig'],
    ];
    const imageDir = 'model/dataset';

    // Your existing function to preprocess the image
    async function processImage(img) {
      return tf.tidy(() => {
        const tensor = tf.browser.fromPixels(img)
          .resizeNearestNeighbor([64, 64])
          .toFloat()
          .div(255.0);
        return tensor.expandDims(0);
      });
    }
async function detectExecutionProvider() {
  // Check for WebGL support
  const webglSupported = (() => {
    try {
      const canvas = document.createElement('canvas');
      return !!(window.WebGLRenderingContext && (
        canvas.getContext('webgl') || canvas.getContext('experimental-webgl')
      ));
    } catch (e) {
      return false;
    }
  })();

  if (webglSupported) {
    return ['webgl'];
  } else if (typeof ort.env.wasm !== 'undefined') {
    // Check if WASM is supported
    return ['wasm'];
  } else {
    // Fallback to CPU
    return ['cpu'];
  }
}

let onnxSession;

async function loadONNXModel(filename) {
  const providers = await detectExecutionProvider();
  console.log('Using ONNX execution provider:', providers[0]);

  onnxSession = await ort.InferenceSession.create(filename, {
    executionProviders: providers
  });
}

async function predictONNX(model, tensor) {
  const transposed = tf.tidy(() => {
    return tensor.transpose([0, 3, 1, 2]);  // [1, H, W, C] â†’ [1, C, H, W]
  });
  const inputData = transposed.dataSync();  // Float32Array
  const inputTensor = new ort.Tensor('float32', inputData, [1, 3, 64, 64]);
  const outputMap = await model.run({ input: inputTensor }); // adjust 'input' name if needed
  tf.dispose(transposed);

  // Assuming single output key:
  //const firstKey = Object.keys(outputMap)[0];
  //return outputMap[firstKey].data;
  return outputMap;
}


    let pageModel, finishModel, indexModel, extraModel, decisionpageModel, steppageModel;
    async function predictModel(model, tensor){
        return await model.predict(tensor).data();
    }
    async function loadModels() {
      await fetchSteppageModel();
      const prefix = "https://autoupdatingbsod.github.io/LSBPSE";
      pageModel =     await tf.loadLayersModel(prefix+'/model/page_type/page-model.json'); // adjust paths
      finishModel =   await tf.loadLayersModel(prefix+'/model/section_type/finish-model.json');
      indexModel =    await tf.loadLayersModel(prefix+'/model/section_type/index-model.json');
      extraModel =    await tf.loadLayersModel(prefix+'/model/section_type/extra-model.json');
      decisionpageModel =  await tf.loadLayersModel(prefix+'/model/section_type/decisionpage-model.json')
      steppageModel = await loadONNXModel("https://github.com/AutoUpdatingBSoD/LSBPSE/releases/download/Testing/steppage.onnx");
      console.log('Models loaded');
    }
    async function handlePDF(file) {
      const pdfData = new Uint8Array(await file.arrayBuffer());
      const pdf = await pdfjsLib.getDocument({ data: pdfData }).promise;

      const canvas = document.createElement('canvas');
      const ctx = canvas.getContext('2d');

      for (let pageNum = 1; pageNum <= pdf.numPages; pageNum++) {
        const page = await pdf.getPage(pageNum);
        const viewport = page.getViewport({ scale: 2.0 });

        canvas.width = viewport.width;
        canvas.height = viewport.height;

        await page.render({ canvasContext: ctx, viewport }).promise;
        const imgTensor = tf.browser.fromPixels(canvas)
          .resizeNearestNeighbor([64, 64])
          .toFloat()
          .div(255)
          .expandDims(0);

        // PAGE PREDICTION (Single label)
        const pagePred = pageModel.predict(imgTensor);
        const pageIndex = (await pagePred.argMax(-1).data());
        const pageLabel = pageLabels[pageIndex];
                    let sectionPred = null;
          const val = pageIndex;
          if (val > 0.5) {
            //document.getElementById('results').innerHTML +=  '- PAGE: '+pageLabel+' '+(val)+'\n';
          
            let idi = null;

          
        switch (pageLabel) {
          case "finish":
            idi = 0;
            sectionPred = await predictModel(finishModel, imgTensor);
            break;
          case "index":
            idi = 1;
            sectionPred = await predictModel(indexModel, imgTensor);
            break;
          case "extra":
            idi = 2;
            sectionPred = await predictModel(extraModel, imgTensor);
            break;
          case "decisionpage":
            idi = 3;
            sectionPred = await predictModel(decisionpageModel, imgTensor);
            break;
          case "steppage":
            idi = 4;
            sectionPred = await predictONNX(steppageModel, imgTensor);  // use ONNX
            break;
        }

          

        }
        // SECTION PREDICTION (Multi-label)
        const sectionCounts = {};
        if (sectionPred) {
           const labelsForPage = sectionLabels[pageIndex]; // use the correct label set
           sectionPred.forEach((prob, i) => {
             if (prob > 0.5 && labelsForPage[i]) {
               const label = labelsForPage[i];
               sectionCounts[label] = (sectionCounts[label] || 0) + 1;
             }
           });
        }

        displayResults(pageNum, pageLabel, sectionCounts);
        tf.dispose([imgTensor, pagePred, sectionPred]);
      }
  }
    async function renderPageToCanvas(pdfPage) {
      const viewport = pdfPage.getViewport({ scale: 2 });
      const canvas = document.createElement('canvas');
      canvas.width = viewport.width;
      canvas.height = viewport.height;
      const context = canvas.getContext('2d');
      await pdfPage.render({ canvasContext: context, viewport: viewport }).promise;
      return canvas;
    }

    function displayResults(pageNum, pageLabel, sectionCounts) {
      const container = document.getElementById('results');
      const block = document.createElement('div');
      block.className = 'page-block';

      let html = '<strong>Page '+pageNum+':</strong> '+pageLabel+'<br>';
      if (Object.keys(sectionCounts).length > 0) {
        html += '<em>Sections:</em><br>';
        for (const [label, count] of Object.entries(sectionCounts)) {
          html += '&nbsp;&nbsp;- '+label+': '+count+'<br>';
        }
      } else {
        html += '<em>No section categories detected above threshold.</em>';
      }

      block.innerHTML = html;
      container.appendChild(block);
    }

    document.getElementById('pdfUpload').addEventListener('change', async (e) => {
      document.getElementById('results').innerHTML = '';
      const file = e.target.files[0];
      if (!file || file.type !== "application/pdf") {
        log.textContent = "Please upload a valid PDF.";
        return;
      }

      log.textContent = `Loading models and reading PDF...\n`;

      const { pageModel, finishModel, indexModel, extraModel, decisionpageModel, steppageModel } = await loadModels();
      const fileURL = URL.createObjectURL(file);
      const pdf = await pdfjsLib.getDocument(fileURL).promise;

      for (let i = 1; i <= pdf.numPages; i++) {
        const page = await pdf.getPage(i);
        const canvas = await renderPageToCanvas(page);
        const tensor = await processImage(canvas);

        const pagePred = await pageModel.predict(tensor).data();
        

        log.textContent += `\nPage ${i} predictions:\n`;

        // Format multi-label output
        for (let idx = 0; idx < pagePred.length; idx++) {
          const val = pagePred[idx];
          if (val > 0.5) {
            log.textContent += ` - PAGE: ${pageCategories[idx]} (${val.toFixed(2)})\n`;
          
            let idi = null;
            let sectionPred = null;
          
            switch (pageCategories[idx]) {
              case "finish":
                idi = 0;
                sectionPred = await predictModel(finishModel, tensor);
                break;
              case "index":
                idi = 1;
                sectionPred = await predictModel(indexModel, tensor);
                break;
              case "extra":
                idi = 2;
                sectionPred = await predictModel(extraModel, tensor);
                break;
              case "decisionpage":
                idi = 3;
                sectionPred = await predictModel(decisionpageModel, tensor);
                break;
              case "steppage":
                idi = 4;
                sectionPred = await predictModel(steppageModel, tensor);
                break;
            }
          
            if (sectionPred) {
              sectionPred.forEach((valy, idxy) => {
                if (valy > 0.5) {
                  log.textContent += `   - SECTION: ${sectionCategories[idi][idxy]} (${valy.toFixed(2)})\n`;
                }
              });
            }
          }
        }


        //sectionPred.forEach((val, idx) => {
        //  if (val > 0.5) log.textContent += ` - SECTION: ${sectionCategories[idx]} (${val.toFixed(2)})\n`;
       // });

        tf.dispose([tensor]);
      }

      log.textContent += `\nDone processing all pages.`;
      if (!file) return;
      await loadModels();
      await handlePDF(file);
    });
  </script>
</body>
</html>
