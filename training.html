
<!DOCTYPE html>
<html>
<head>
    <title>LEGO Multi-Label Classifier - Training</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
    <style>
        body { font-family: sans-serif; padding: 20px; }
    </style>
</head>
<body>
    <h1>Training LEGO Classifier</h1>
    <pre id="log"></pre>

    <script>
const IMG_WIDTH = 1024;
const IMG_HEIGHT = 768;

    
// Example values
const pageCategories = ['finish', 'index', 'extra', 'decisionpage', 'steppage'];
const NUM_CLASSES = pageCategories.length;

// Build model
function buildPageModel(is) {
  const model = tf.sequential();
  model.add(tf.layers.conv2d({ filters: 16, kernelSize: 3, activation: 'relu', inputShape: [IMG_WIDTH, IMG_HEIGHT, 3] }));
  model.add(tf.layers.maxPooling2d({ poolSize: 2 }));
  model.add(tf.layers.flatten());
  model.add(tf.layers.dense({ units: 64, activation: 'relu' }));
  model.add(tf.layers.dense({ units: is, activation: 'softmax' }));

  model.compile({
    optimizer: tf.train.adam(),
    loss: 'categoricalCrossentropy',
    metrics: ['accuracy']
  });

  return model;
}

    const imageDir = 'https://autoupdatingbsod.github.io/LSBPSE/model/dataset';
    const indicesp = [2, 4, 66, 2, 346]
const backends = ['webgl', 'wasm', 'cpu'];

async function loadbackend(){
  for (const backend of backends) {
    try {
      await tf.setBackend(backend);
      await tf.ready();
      console.log('Using backend: '+backend);
      break;
    } catch (e) {
      console.warn('Backend '+backend+' not available:, e');
    }
  }
}

async function loadImage(src) {
    return new Promise((resolve) => {
        const img = new Image();
        img.crossOrigin = 'anonymous';
        img.onload = () => resolve(img);
        img.src = src;
    });
}

async function processImage(img) {
  return tf.tidy(() =>
    tf.browser.fromPixels(img)
      .resizeNearestNeighbor([IMG_HEIGHT, IMG_WIDTH])
      .toFloat()
      .div(255.0)
      .expandDims(0)
  );
}

function buildModel(outputSize) {
    const model = tf.sequential();

    model.add(tf.layers.conv2d({
        inputShape: [IMG_HEIGHT, IMG_WIDTH, 3],
        filters: 16,
        kernelSize: 3,
        activation: 'relu'
    }));
    model.add(tf.layers.maxPooling2d({ poolSize: 2 }));
    model.add(tf.layers.flatten());
    model.add(tf.layers.dense({ units: 64, activation: 'relu' }));
    model.add(tf.layers.dense({ units: outputSize, activation: 'softmax' }));

model.compile({
  optimizer: tf.train.adam(),
  loss: 'categoricalCrossentropy', // NEW
  metrics: ['accuracy']
});


    return model;
}

function createMultiLabelVector(labels, categoryCount) {
    const vector = new Array(categoryCount).fill(0);
    for (const label of labels) {
        if (label >= 0 && label < categoryCount) {
            vector[label] = 1;
        }
    }
    return vector;
}

async function trainModels() {
    const log = document.getElementById('log');
    log.textContent = 'Loading images...\n';
    await loadbackend();

    const pageXs = [], pageYs = [], sectionXs = [], sectionYs = [];

    for (let i = 0; i < indicesp.length; i++) {
        const label = i;
        const category = pageCategories[label];

        for (let j = 1; j <= indicesp[i]; j++) {
            const path = imageDir+'/'+category+'/'+category+' '+j+'.png';
            const img = await loadImage(path);
            const tensor = await processImage(img);

            pageXs.push(tensor);
            pageYs.push(createMultiLabelVector([label], pageCategories.length));
        }
        log.textContent += 'Loaded ' + category + '\n';
    }

    log.textContent += "Done\n";

    const pageModel = buildPageModel(pageCategories.length);
    await pageModel.fit(tf.concat(pageXs), tf.tensor2d(pageYs), {
    epochs: 200,
    batchSize: 32,
    shuffle: true,
    validationSplit: 0.1,
    callbacks: [
        tf.callbacks.earlyStopping({ monitor: 'loss', patience: 10, restoreBestWeight: true }),
        {
            onEpochEnd: (epoch, logs) => {
              log.textContent += `Epoch ${epoch + 1}: loss = ${logs.loss.toFixed(4)}, acc = ${logs.acc?.toFixed(4)}\n`;
            }
          }
        ] 
    })
  });
    await pageModel.save('downloads://page-model');

    log.textContent += 'Model trained and saved!';
    pageXs.forEach(t => t.dispose());

}



// Build section model
function buildSectionModel(is) {
  const model = tf.sequential();
  model.add(tf.layers.conv2d({ filters: 16, kernelSize: 3, activation: 'relu', inputShape: 
<!DOCTYPE html>
<html>
<head>
    <title>LEGO Multi-Label Classifier - Training</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
    <style>
        body { font-family: sans-serif; padding: 20px; }
    </style>
</head>
<body>
    <h1>Training LEGO Classifier</h1>
    <pre id="log"></pre>

    <script>
const IMG_WIDTH = 1024;
const IMG_HEIGHT = 768;

    
// Example values
const pageCategories = ['finish', 'index', 'extra', 'decisionpage', 'steppage'];
const NUM_CLASSES = pageCategories.length;

// Build model
function buildPageModel(is) {
  const model = tf.sequential();
  model.add(tf.layers.conv2d({ filters: 16, kernelSize: 3, activation: 'relu', inputShape: [IMG_HEIGHT, IMG_WIDTH, 3] }));
  model.add(tf.layers.maxPooling2d({ poolSize: 2 }));
  model.add(tf.layers.flatten());
  model.add(tf.layers.dense({ units: 64, activation: 'relu' }));
  model.add(tf.layers.dense({ units: is, activation: 'softmax' }));

  model.compile({
    optimizer: tf.train.adam(),
    loss: 'categoricalCrossentropy',
    metrics: ['accuracy']
  });

  return model;
}

    const imageDir = 'https://autoupdatingbsod.github.io/LSBPSE/model/dataset';
    const indicesp = [2, 4, 66, 2, 346]
const backends = ['webgl', 'wasm', 'cpu'];

async function loadbackend(){
  for (const backend of backends) {
    try {
      await tf.setBackend(backend);
      await tf.ready();
      console.log('Using backend: '+backend);
      break;
    } catch (e) {
      console.warn('Backend '+backend+' not available:, e');
    }
  }
}

async function loadImage(src) {
    return new Promise((resolve) => {
        const img = new Image();
        img.crossOrigin = 'anonymous';
        img.onload = () => resolve(img);
        img.src = src;
    });
}

async function processImage(img) {
  return tf.tidy(() =>
    tf.browser.fromPixels(img)
      .resizeNearestNeighbor([IMG_HEIGHT, IMG_WIDTH])
      .toFloat()
      .div(255.0)
      .expandDims(0)
  );
}

function buildModel(outputSize) {
    const model = tf.sequential();

    model.add(tf.layers.conv2d({
        inputShape: [IMG_HEIGHT, IMG_WIDTH, 3],
        filters: 16,
        kernelSize: 3,
        activation: 'relu'
    }));
    model.add(tf.layers.maxPooling2d({ poolSize: 2 }));
    model.add(tf.layers.flatten());
    model.add(tf.layers.dense({ units: 64, activation: 'relu' }));
    model.add(tf.layers.dense({ units: outputSize, activation: 'softmax' }));

model.compile({
  optimizer: tf.train.adam(),
  loss: 'categoricalCrossentropy', // NEW
  metrics: ['accuracy']
});


    return model;
}

function createMultiLabelVector(labels, categoryCount) {
    const vector = new Array(categoryCount).fill(0);
    for (const label of labels) {
        if (label >= 0 && label < categoryCount) {
            vector[label] = 1;
        }
    }
    return vector;
}

async function trainModels() {
    const log = document.getElementById('log');
    log.textContent = 'Loading images...\n';
    await loadbackend();

    const pageXs = [], pageYs = [], sectionXs = [], sectionYs = [];

    for (let i = 0; i < indicesp.length; i++) {
        const label = i;
        const category = pageCategories[label];

        for (let j = 1; j <= indicesp[i]; j++) {
            const path = imageDir+'/'+category+'/'+category+' '+j+'.png';
            const img = await loadImage(path);
            const tensor = await processImage(img);

            pageXs.push(tensor);
            pageYs.push(createMultiLabelVector([label], pageCategories.length));
        }
        log.textContent += 'Loaded ' + category + '\n';
    }

    log.textContent += "Done\n";

    const pageModel = buildPageModel(pageCategories.length);
    await pageModel.fit(tf.concat(pageXs), tf.tensor2d(pageYs), {
    epochs: 200,
    batchSize: 32,
    shuffle: true,
    validationSplit: 0.1,
    callbacks: [
        tf.callbacks.earlyStopping({ monitor: 'loss', patience: 10, restoreBestWeight: true }),
        {
            onEpochEnd: (epoch, logs) => {
              log.textContent += `Epoch ${epoch + 1}: loss = ${logs.loss.toFixed(4)}, acc = ${logs.acc?.toFixed(4)}\n`;
            }
          }
        ] 
    })
  });
    await pageModel.save('downloads://page-model');

    log.textContent += 'Model trained and saved!';
    pageXs.forEach(t => t.dispose());

}



// Build section model
function buildSectionModel(is) {
  const model = tf.sequential();
  model.add(tf.layers.conv2d({ filters: 16, kernelSize: 3, activation: 'relu', inputShape: [IMG_HEIGHT, IMG_WIDTH, 3] }));
  model.add(tf.layers.maxPooling2d({ poolSize: 2 }));
  model.add(tf.layers.flatten());
  model.add(tf.layers.dense({ units: 64, activation: 'relu' }));
  model.add(tf.layers.dense({ units: is, activation: 'sigmoid' }));

  model.compile({
    optimizer: tf.train.adam(),
    loss: 'binaryCrossentropy',
    metrics: ['accuracy']
  });

  return model;
}

trainModels();
    </script>
</body>
</html>
 }));
  model.add(tf.layers.maxPooling2d({ poolSize: 2 }));
  model.add(tf.layers.flatten());
  model.add(tf.layers.dense({ units: 64, activation: 'relu' }));
  model.add(tf.layers.dense({ units: is, activation: 'sigmoid' }));

  model.compile({
    optimizer: tf.train.adam(),
    loss: 'binaryCrossentropy',
    metrics: ['accuracy']
  });

  return model;
}

trainModels();
    </script>
</body>
</html>
